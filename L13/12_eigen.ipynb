{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "Kmym8wb6--nZ",
    "outputId": "39022754-57e0-4def-bb5e-30ade170fa1c"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/cs357/demos-cs357.git\n",
    "    !mv demos-cs357/figures/ .\n",
    "    !mv demos-cs357/additional_files/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CSnRbDT7--n3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as sla\n",
    "import numpy.linalg as la\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyjDdKli--oK"
   },
   "source": [
    "# Obtaining eigenvalues and eigenvectors numerically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUcxABaj--oP"
   },
   "source": [
    "We want to prepare a matrix with deliberately chosen eigenvalues. Let's use diagonalization to write the matrix $\\mathbf{A}$:\n",
    "\n",
    "$$ \\mathbf{A} = \\mathbf{U D U}^{-1} $$\n",
    "\n",
    "where we set ${\\bf D}$ to be a known matrix with the pre-defined eigenvalues:\n",
    "\n",
    "```python\n",
    "D = np.diag([lambda1, lambda2, ..., lambdan])\n",
    "```\n",
    "\n",
    "We need to generate a matrix $\\mathbf{U}$ that has an inverse. Orthogonal matrices are a great option here, since $\\mathbf{U}^{-1} = \\mathbf{U}^T$. We use QR decomposition to get an orthogonal matrix (you don't need to understand this method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2CVW7zSS--oS"
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "X = np.random.rand(n,n)\n",
    "U,_ = sla.qr(X)\n",
    "\n",
    "D = np.diag([6,2,4,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZxF6tz7A--oi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70627274  0.17104307  0.65147049 -0.21796625]\n",
      " [-0.03525445 -0.22295305 -0.290768   -0.92978655]\n",
      " [-0.68623417  0.07296112 -0.68825246  0.22375856]\n",
      " [-0.17034848 -0.95692888  0.13171455  0.19473005]]\n"
     ]
    }
   ],
   "source": [
    "print(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2yLwNIG--oz"
   },
   "source": [
    "Now we can use diagonalization to write $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RfazhMIk--o0"
   },
   "outputs": [],
   "source": [
    "A = U@D@U.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTqX49IS--o6"
   },
   "source": [
    "And we can check that the eigenvalues are indeed what we expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hJo6_MsV--o7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 4. 6. 7.]\n",
      "[[-0.17104307  0.65147049 -0.70627274  0.21796625]\n",
      " [ 0.22295305 -0.290768   -0.03525445  0.92978655]\n",
      " [-0.07296112 -0.68825246 -0.68623417 -0.22375856]\n",
      " [ 0.95692888  0.13171455 -0.17034848 -0.19473005]]\n"
     ]
    }
   ],
   "source": [
    "eigl, eigv = la.eig(A)\n",
    "print(eigl)\n",
    "print(eigv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBZ2P6at--pA"
   },
   "source": [
    "We want to find the eigenvector corresponding to the largest eigenvalue in magnitude. For that, we can use `np.argsort`, which returns the indices that sort the array in ascending order. Hence, we are interested in the last entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F2zZSlxW--pB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "eig_index_sort = np.argsort(abs(eigl))\n",
    "print(eig_index_sort)\n",
    "eigpos = eig_index_sort[-1]\n",
    "print(eigpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q255sulu--pF"
   },
   "source": [
    "Recall that eigenvectors are stored as columns! Hence this would be the eigenvector corresponding to the largest (in magnitude) eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WD4Zc8wR--pG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21796625,  0.92978655, -0.22375856, -0.19473005])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigv[:,eigpos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zHBZGOl--pM"
   },
   "source": [
    "# Power Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXdvnV5r--pN"
   },
   "source": [
    "Let's pick an initial vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NQy7_M5M--pO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.60712982,  0.91810464,  0.65665591,  0.02585147])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = np.random.randn(n)\n",
    "x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgQhV7sZ--pT"
   },
   "source": [
    "And we perform matrix-vector multiplications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MAkLX767--pU"
   },
   "outputs": [],
   "source": [
    "x = x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dwDc_b9b--pZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.87584449  5.13739986  2.36649525 -0.75538795]\n"
     ]
    }
   ],
   "source": [
    "x = A@x\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epFzIOzk--pg"
   },
   "source": [
    "Power iteration should converge to a multiple of the eigenvector ${\\bf u}_1$ corresponding to largest eigenvalue (in magnitude)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RXQcr01--pi"
   },
   "source": [
    "$$ {\\bf x}_k = (\\lambda_1)^k \\left[ \\alpha_1 {\\bf u}_1 + \\alpha_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k{\\bf u}_2 + ...  \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDlMiG2f--pk"
   },
   "source": [
    "Let's implememt power iteration. We simply perform multiple matrix vector multiplications using a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7N2Ua1iF--pm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.87584449  5.13739986  2.36649525 -0.75538795]\n",
      "[-4.20551847 31.43657239  7.35646011 -6.32230899]\n",
      "[  4.79016171 203.20278274  13.76028981 -43.05278451]\n",
      "[ 165.51441763 1357.40279927  -58.34546389 -286.35156146]\n",
      "[ 1664.75241113  9245.95041113 -1046.12351513 -1926.85489779]\n",
      "[ 13562.80212879  63703.00183716  -9981.23483541 -13159.73865806]\n",
      "[101918.57016535 441834.64382275 -81134.09445591 -90873.02786815]\n",
      "[ 737453.17469278 3076345.0032812  -616765.63125079 -631887.20022582]\n",
      "[ 5235034.08570971 21467349.9689207  -4535205.00372882 -4411552.95378089]\n",
      "[ 3.67975507e+07  1.49996414e+08 -3.27529370e+07 -3.08670702e+07]\n",
      "[ 2.57357792e+08  1.04883344e+09 -2.34107071e+08 -2.16214062e+08]\n",
      "[ 1.79559941e+09  7.33701914e+09 -1.66295815e+09 -1.51528094e+09]\n",
      "[ 1.25155481e+10  5.13383767e+10 -1.17667164e+10 -1.06213332e+10]\n",
      "[ 8.72140866e+10  3.59276617e+11 -8.30460991e+10 -7.44502403e+10]\n",
      "[ 6.07838656e+11  2.51451429e+12 -5.85089308e+11 -5.21816008e+11]\n",
      "[ 4.23774511e+12  1.75995882e+13 -4.11699327e+12 -3.65693362e+12]\n",
      "[ 2.95567999e+13  1.23187128e+14 -2.89422353e+13 -2.56248073e+13]\n",
      "[ 2.06234451e+14  8.62258279e+14 -2.03315636e+14 -1.79535054e+14]\n",
      "[ 1.43958766e+15  6.03553157e+15 -1.42745057e+15 -1.25772888e+15]\n",
      "[ 1.00524942e+16  4.22471959e+16 -1.00172854e+16 -8.81006346e+15]\n",
      "[ 7.02185495e+16  2.95721753e+17 -7.02705249e+16 -6.17064535e+16]\n",
      "[ 4.90631610e+17  2.07000270e+18 -4.92785793e+17 -4.32162196e+17]\n",
      "[ 3.42901276e+18  1.44897300e+19 -3.45483309e+18 -3.02644136e+18]\n",
      "[ 2.39705618e+19  1.01426410e+20 -2.42157461e+19 -2.11929409e+19]\n",
      "[ 1.67598462e+20  7.09974811e+20 -1.69701387e+20 -1.48397757e+20]\n",
      "[ 1.17201519e+21  4.96976386e+21 -1.18905540e+21 -1.03906756e+21]\n",
      "[ 8.19705716e+21  3.47879903e+22 -8.33025682e+21 -7.27517354e+21]\n",
      "[ 5.73370855e+22  2.43513801e+23 -5.83529910e+22 -5.09364223e+22]\n",
      "[ 4.01105633e+23  1.70458385e+24 -4.08718014e+23 -3.56616217e+23]\n",
      "[ 2.80621533e+24  1.19320106e+25 -2.86250823e+24 -2.49668115e+24]\n",
      "[ 1.96343614e+25  8.35236162e+25 -2.00464491e+25 -1.74789741e+25]\n",
      "[ 1.37385650e+26  5.84662569e+26 -1.40378487e+26 -1.22366056e+26]\n",
      "[ 9.61370245e+26  4.09262152e+27 -9.82969452e+26 -8.56641817e+26]\n",
      "[ 6.72761582e+27  2.86482520e+28 -6.88270632e+27 -5.99696930e+27]\n",
      "[ 4.70814551e+28  2.00537172e+29 -4.81904648e+28 -4.19816446e+28]\n",
      "[ 3.29499050e+29  1.40375665e+30 -3.37402376e+29 -2.93888670e+29]\n",
      "[ 2.30606653e+30  9.82627523e+30 -2.36223136e+30 -2.05732363e+30]\n",
      "[ 1.61399048e+31  6.87837988e+31 -1.65381079e+31 -1.44018831e+31]\n",
      "[ 1.12963968e+32  4.81485824e+32 -1.15781685e+32 -1.00816888e+32]\n",
      "[ 7.90655583e+32  3.37039617e+33 -8.10561375e+32 -7.05740452e+32]\n",
      "Exact eigenvalue =  [ 0.21796625  0.92978655 -0.22375856 -0.19473005]\n"
     ]
    }
   ],
   "source": [
    "x = x0\n",
    "for i in range(40):\n",
    "    x = A @ x\n",
    "    print(x)\n",
    "    \n",
    "print('Exact eigenvalue = ',eigv[:,eigpos])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCYaxjBh--pu"
   },
   "source": [
    "* What's the problem with this method?\n",
    "* Does anything useful come of this?\n",
    "* How do we fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAlSe_7z--pv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tLpQYKL--pz"
   },
   "source": [
    "We can get the corresponding eigenvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FqC6gHO9--pz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.999999953314585"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x,A@x)/np.dot(x,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTowzjqE--p2"
   },
   "source": [
    "# Normalized power iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeXcqqFN--p3"
   },
   "source": [
    "Back to the beginning: Reset to the initial vector and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zot-U1r9--p3"
   },
   "outputs": [],
   "source": [
    "x = x0/la.norm(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KQ5GQGP--p6"
   },
   "source": [
    "Implement normalized power iteration. We will start with 10 iterations, and see what happens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5h2PMpW--p7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = x0/la.norm(x0)\n",
    "\n",
    "for i in range(20):\n",
    "    x = A @ x\n",
    "    nrm = la.norm(x)\n",
    "    x = x/nrm\n",
    "    print(x)\n",
    "\n",
    "print('exact = ' ,eigv[:,eigpos])\n",
    "\n",
    "print('eig_approx = ', (x.T@A@x)/(x.T@x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCVHmQRx--p9"
   },
   "source": [
    "### What if the starting guess does not have any component of ${\\bf u}_1$, i.e., if $\\alpha_1 = 0$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPrOl9Q0--p9"
   },
   "source": [
    "$$ {\\bf x}_k = (\\lambda_1)^k  \\alpha_1 {\\bf u}_1 + (\\lambda_1)^k  \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k \\alpha_2 {\\bf u}_2 + (\\lambda_1)^k \\left[   \\left(\\frac{\\lambda_3}{\\lambda_1}\\right)^k \\alpha_3{\\bf u}_3 +  ...  \\right] $$\n",
    "\n",
    "In theory (or infinite precision calculations), if $\\alpha_1=0$, power iteration will converge to a vector that is a multiple of the eigenvector ${\\bf u}_2$. \n",
    "\n",
    "\n",
    "In practice, it is unlikely that a random vector ${\\bf x}_0$ will not have any component of ${\\bf u}_1$. In the chances that happens, finite operations during the iterative process will usually introduce such component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fe4yNlA--p-"
   },
   "source": [
    "### Creating a matrix where the dominant eigenvalue is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icqJvFy9--p-"
   },
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuWyzB9h--qA"
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "    \n",
    "D = np.diag([-5,2,4,3])\n",
    "\n",
    "A = U@D@U.T\n",
    "\n",
    "eigl, eigv = la.eig(A)\n",
    "\n",
    "eig_index_sort = np.argsort(abs(eigl))\n",
    "eigpos = eig_index_sort[-1]\n",
    "\n",
    "print(eigl)\n",
    "print(eigv[:,eigpos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dor-PBB--qF"
   },
   "outputs": [],
   "source": [
    "x = x0/la.norm(x0)\n",
    "\n",
    "for i in range(40):\n",
    "    x = A @ x\n",
    "    nrm = la.norm(x)\n",
    "    x = x/nrm\n",
    "    print(x)\n",
    "\n",
    "print('exact = ' ,eigv[:,eigpos])\n",
    "\n",
    "print('eig_approx = ', np.dot(x,A@x)/np.dot(x,x))\n",
    "\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EST75b6E--qJ"
   },
   "source": [
    "What is happening here? Note that the scalar that multiplies the eigenvector ${\\bf u}_1$ in \n",
    "\n",
    "$$ {\\bf x}_k = (\\lambda_1)^k  \\alpha_1 {\\bf u}_1 + (\\lambda_1)^k  \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k \\alpha_2 {\\bf u}_2 + (\\lambda_1)^k \\left[   \\left(\\frac{\\lambda_3}{\\lambda_1}\\right)^k \\alpha_3{\\bf u}_3 +  ...  \\right] $$\n",
    "\n",
    "is $(\\lambda_1)^k$, and hence if the eigenvalue  $\\lambda_1$ is negative, the solution of power iteration will converge to the eigenvector, but with alternating signs, i.e., ${\\bf u}_1$ and $-{\\bf u}_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5DKjuaR--qK"
   },
   "source": [
    "### When dealing with dominant eigenvalues of multiplicity greater than 1: $|\\lambda_1| = |\\lambda_2| $ and $ \\lambda_1, \\lambda_2 > 0 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MR5SFKe3--qK"
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "\n",
    "D = np.diag([5,5,2,1])\n",
    "\n",
    "A = U@D@U.T\n",
    "\n",
    "eigl, eigv = la.eig(A)\n",
    "\n",
    "print(eigl)\n",
    "print(eigv[:,2])\n",
    "print(eigv[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okIxS3Rj--qM"
   },
   "outputs": [],
   "source": [
    "x = x0/la.norm(x0)\n",
    "\n",
    "for i in range(40):\n",
    "    x = A @ x\n",
    "    nrm = la.norm(x)\n",
    "    x = x/nrm\n",
    "    print(x)\n",
    "\n",
    "print('u1_exact = ' ,eigv[:,2])\n",
    "print('u2_exact = ' ,eigv[:,3])\n",
    "\n",
    "print('eig_approx = ', np.dot(x,A@x)/np.dot(x,x))\n",
    "\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SguilJBi--qQ"
   },
   "source": [
    "In general, power method converges to:\n",
    "\n",
    "$$ {\\bf x}_k = (\\lambda_1)^k  \\alpha_1 {\\bf u}_1 + (\\lambda_1)^k  \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k \\alpha_2 {\\bf u}_2 + (\\lambda_1)^k \\left[   \\left(\\frac{\\lambda_3}{\\lambda_1}\\right)^k \\alpha_3{\\bf u}_3 +  ...  \\right] $$\n",
    "\n",
    "However if $|\\lambda_1| = |\\lambda_2| $ and $ \\lambda_1, \\lambda_2 > 0 $, we get:\n",
    "\n",
    "$$ {\\bf x}_k = (\\lambda_1)^k \\left( \\alpha_1 {\\bf u}_1 + \\alpha_2 {\\bf u}_2 \\right) + \\left[ ...  \\right] $$\n",
    "\n",
    "and hence the solution of power iteration will converge to a multiple of the linear combination of the eigenvectors ${\\bf u}_1$ and ${\\bf u}_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fZXQ2QJ--qQ"
   },
   "source": [
    "### When dealing with dominant eigenvalues of multiplicity greater than 1: $|\\lambda_1| = |\\lambda_2| $ and $ \\lambda_1, \\lambda_2 < 0 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXVJFNyH--qQ"
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "\n",
    "D = np.diag([-5,-5,2,1])\n",
    "\n",
    "A = U@D@U.T\n",
    "\n",
    "eigl, eigv = la.eig(A)\n",
    "\n",
    "print(eigl)\n",
    "print(eigv[:,2])\n",
    "print(eigv[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0OsE3rS--qU"
   },
   "outputs": [],
   "source": [
    "x = x0/la.norm(x0)\n",
    "\n",
    "for i in range(40):\n",
    "    x = A @ x\n",
    "    nrm = la.norm(x)\n",
    "    x = x/nrm\n",
    "    print(x)\n",
    "\n",
    "print('u1_exact = ' ,eigv[:,2])\n",
    "print('u2_exact = ' ,eigv[:,3])\n",
    "\n",
    "print('eig_approx = ', np.dot(x,A@x)/np.dot(x,x))\n",
    "\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pse34-Ta--qX"
   },
   "source": [
    "In general, power method converges to:\n",
    "\n",
    "$$ {\\bf x}_k = (\\lambda_1)^k  \\alpha_1 {\\bf u}_1 + (\\lambda_1)^k  \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k \\alpha_2 {\\bf u}_2 + (\\lambda_1)^k \\left[   \\left(\\frac{\\lambda_3}{\\lambda_1}\\right)^k \\alpha_3{\\bf u}_3 +  ...  \\right] $$\n",
    "\n",
    "However if $|\\lambda_1| = |\\lambda_2| $ and $ \\lambda_1, \\lambda_2 < 0 $, we get:\n",
    "\n",
    "$$ {\\bf x}_k = \\pm |\\lambda_1|^k \\left( \\alpha_1 {\\bf u}_1 + \\alpha_2 {\\bf u}_2 \\right) + \\left[ ...  \\right] $$\n",
    "\n",
    "and hence the solution of power iteration will converge to a multiple of the linear combination of the eigenvectors ${\\bf u}_1$ and ${\\bf u}_2$, but the signs will flip at each step of the iterative method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO3IXfOa--qX"
   },
   "source": [
    "### When dealing with dominant eigenvalues of multiplicity greater than 1: $|\\lambda_1| = |\\lambda_2| $ and $ \\lambda_1 , \\lambda_2 $ have opposite signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGf9pWKz--qX"
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "\n",
    "D = np.diag([-5,5,2,1])\n",
    "\n",
    "A = U@D@U.T\n",
    "\n",
    "eigl, eigv = la.eig(A)\n",
    "\n",
    "print(eigl)\n",
    "print(eigv[:,0])\n",
    "print(eigv[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rmir52oV--qa"
   },
   "outputs": [],
   "source": [
    "x = x0/la.norm(x0)\n",
    "\n",
    "for i in range(40):\n",
    "    x = A @ x\n",
    "    nrm = la.norm(x)\n",
    "    x = x/nrm\n",
    "    print(x)\n",
    "\n",
    "print('u1_exact = ' ,eigv[:,2])\n",
    "print('u2_exact = ' ,eigv[:,3])\n",
    "\n",
    "print('eig_approx = ', np.dot(x,A@x)/np.dot(x,x))\n",
    "\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H33VFzHj--qc"
   },
   "source": [
    "In general, power method converges to:\n",
    "\n",
    "$$ {\\bf x}_k = (\\lambda_1)^k  \\alpha_1 {\\bf u}_1 + (\\lambda_1)^k  \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k \\alpha_2 {\\bf u}_2 + (\\lambda_1)^k \\left[   \\left(\\frac{\\lambda_3}{\\lambda_1}\\right)^k \\alpha_3{\\bf u}_3 +  ...  \\right] $$\n",
    "\n",
    "However if $|\\lambda_1| = |\\lambda_2| $, $ \\lambda_1, \\lambda_2$ have opposite signs, we get:\n",
    "\n",
    "$$ {\\bf x}_k = \\pm |\\lambda_1|^k \\left( \\alpha_1 {\\bf u}_1 \\pm \\alpha_2 {\\bf u}_2 \\right) + \\left[ ...  \\right] $$\n",
    "\n",
    "and hence power iteration does not converge to one solution. Indeed, the method oscilates between two linear combination of eigenvectors, and fails to give the correct eigenvalue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJREbdyJ--qc"
   },
   "source": [
    "### Summary - Pitfalls of power iteration:\n",
    "\n",
    "- Risk of eventual overflow. Use normalized power iteration to avoid this.\n",
    "\n",
    "\n",
    "- If the initial guess has $\\alpha_1 = 0$, the method will converge to multiple of eigenvector ${\\bf u}_2$ if infinite precision computation is used. In practice (in finite precision computations), this will not be an issue, and the method will converge to multiple of eigenvector ${\\bf u}_1$.\n",
    "\n",
    "\n",
    "- If the two largest eigenvalues are equal in magnitude, power iteration will converge to a vector that is a linear combination of the corresponding eigenvectors (or fail to converge). This is a real problem that cannot be discounted in practice. Other methods should be used in this case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjFGbf9v--qc"
   },
   "source": [
    "# Estimating the eigenvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZ9TrIxe--qd"
   },
   "source": [
    "We want to approximate the eigenvalue ${\\bf u}_1$ using the solution of power iteration\n",
    "\n",
    "$$ {\\bf x}_k = (\\lambda_1)^k  \\alpha_1 {\\bf u}_1 + (\\lambda_1)^k  \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k \\alpha_2 {\\bf u}_2 + (\\lambda_1)^k \\left[   \\left(\\frac{\\lambda_3}{\\lambda_1}\\right)^k \\alpha_3{\\bf u}_3 +  ...  \\right] $$\n",
    "\n",
    "\n",
    "$ {\\bf x}_k $ approaches a multiple of the eigenvector ${\\bf u}_1$ as $k \\rightarrow \\infty$, hence\n",
    "\n",
    "$$ {\\bf x}_k  =   (\\lambda_1)^k  \\alpha_1 {\\bf u}_1 $$\n",
    "\n",
    "but also  \n",
    "\n",
    "$$ {\\bf x}_{k+1}  =   (\\lambda_1)^{k+1}  \\alpha_1 {\\bf u}_1 \\Longrightarrow {\\bf x}_{k+1} = \\lambda_1 {\\bf x}_{k} $$\n",
    "\n",
    "We can then approximate $\\lambda_1$ as the ratio of corresponding entries of the vectors ${\\bf x}_{k+1}$ and ${\\bf x}_{k}$, i.e., \n",
    "\n",
    "$$ \\lambda_1 \\approx \\frac{({\\bf x}_{k+1})_j } { ({\\bf x}_{k})_j }$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Bb9igEq--qd"
   },
   "source": [
    "# Error of Power Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO73Rhsm--qd"
   },
   "source": [
    "We define the approximated eigenvector as \n",
    "\n",
    "$$ {\\bf u}_{approx} = \\frac{{\\bf x}_k } { (\\lambda_1)^k  \\alpha_1} $$\n",
    "\n",
    "and hence the error becomes the part of the power iteration solution that was neglected, i.e.,\n",
    "\n",
    "$$ {\\bf e} =  {\\bf u}_{approx} - {\\bf u}_1 = \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k \\frac{\\alpha_2}{\\alpha_1} {\\bf u}_2 +  \\left[   \\left(\\frac{\\lambda_3}{\\lambda_1}\\right)^k \\frac{\\alpha_3}{\\alpha_1}{\\bf u}_3 +  ...  \\right]  $$\n",
    "\n",
    "and when $k$ is large, we can write (again, we are assuming that $|\\lambda_1| > |\\lambda_2|  \\ge |\\lambda_3|  \\ge |\\lambda_4| ... $ \n",
    "\n",
    "$${\\bf e}_k \\approx \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^k \\frac{\\alpha_2}{\\alpha_1} {\\bf u}_2 $$\n",
    "\n",
    "And when we take the norm of the error\n",
    "\n",
    "$$||{\\bf e}_k|| \\approx \\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^k \\left|\\frac{\\alpha_2}{\\alpha_1}\\right| ||{\\bf u}_2 || \\rightarrow ||{\\bf e}_k|| = O\\left(\\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^k \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zgdouyh--qe"
   },
   "source": [
    "# Convergence of Power Iteration\n",
    "\n",
    "We want to see what happens to the error from one iteration of the other of power iteration\n",
    "\n",
    "$$ \\frac{||{\\bf e}_{k+1}||}{||{\\bf e}_{k}||} = \n",
    "\\frac{\\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^{k+1} \\left|\\frac{\\alpha_2}{\\alpha_1}\\right|  }{\\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^k \\left|\\frac{\\alpha_2}{\\alpha_1}\\right| } = \\frac{\\lambda_2}{\\lambda_1} $$ \n",
    "\n",
    "Or in other words, we can say that the error decreases by a **constant** value, given as $\\frac{\\lambda_2}{\\lambda_1} $, at each iteration.\n",
    "\n",
    "** Power method has LINEAR convergence! **\n",
    "\n",
    "$$ ||{\\bf e}_{k+1}|| = \\frac{\\lambda_2}{\\lambda_1} ||{\\bf e}_{k}||$$   \n",
    "or we can also write $$ ||{\\bf e}_{k+1}|| = \\left(\\frac{\\lambda_2}{\\lambda_1} \\right)^k||{\\bf e}_{0}||$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnkMyMK6--qe"
   },
   "source": [
    "# Simple Example:\n",
    "Suppose you are given a matrix with eigenvalues:\n",
    "\n",
    "$$[3,4,5]$$\n",
    "\n",
    "You use normalized power iteration to approximate one of the eigenvectors, which is given as ${\\bf x}$, and we assume $||{\\bf x} || = 1$.\n",
    "\n",
    "You knew the norm of the error of the initial guess was given as\n",
    "\n",
    "$$|| {\\bf e}_0 || = ||{\\bf x} - {\\bf x}_0 || = 0.3 $$\n",
    "\n",
    "How big will be the error after three rounds of power iteration? (Since all vectors have norm 1, the absolute and relative error are the same)\n",
    "\n",
    "\n",
    "$$|| {\\bf e}_3 || = \\left| \\frac{4}{5} \\right|^3 || {\\bf e}_0 || = 0.3 \\left| \\frac{4}{5} \\right|^3  = 0.1536 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VM9WcZj0--qe"
   },
   "source": [
    "# Convergence plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fY5gvqs9--qf"
   },
   "outputs": [],
   "source": [
    "n=4\n",
    "\n",
    "lambda_array_ordered = [7, 3, -2, 1]\n",
    "\n",
    "X = np.random.rand(n,n)\n",
    "U,_ = sla.qr(X)\n",
    "D = np.diag(lambda_array_ordered)\n",
    "A = U@D@U.T\n",
    "eigl, eigv = la.eig(A)\n",
    "\n",
    "eig_index_sort = np.argsort(abs(eigl))\n",
    "eigpos = eig_index_sort[-1]\n",
    "u1_exact = eigv[:,eigpos]\n",
    "\n",
    "print('Largest lambda = ', lambda_array_ordered[0])\n",
    "print('Eigenvector = ', u1_exact)\n",
    "print('Convergence rate = ', lambda_array_ordered[1]/lambda_array_ordered[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQAZAfSZ--qh"
   },
   "outputs": [],
   "source": [
    "# Generate normalized initial guess\n",
    "x0 = np.random.random(n)\n",
    "x = x0/la.norm(x0)\n",
    "\n",
    "count = 0\n",
    "diff  = 1\n",
    "eigs  = [x[0]]\n",
    "error = [np.abs( eigs[-1]  - lambda_array_ordered[0] )]\n",
    "\n",
    "# We will use as stopping criteria the change in the\n",
    "# approximation for the eigenvalue\n",
    "\n",
    "while (diff > 1e-6 and count < 100):\n",
    "    count += 1\n",
    "    xnew = A@x #xk+1 = A xk\n",
    "    eigs.append(xnew[0]/x[0])\n",
    "    x = xnew/la.norm(xnew)    \n",
    "    diff  = np.abs( eigs[-1]  - eigs[-2] )\n",
    "    error.append( np.abs( eigs[-1]  - lambda_array_ordered[0] ) )    \n",
    "    print(\"% 10f % 2e % 2f\" %(eigs[-1], error[-1], error[-1]/error[-2])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OuyxzD2Y--qi"
   },
   "outputs": [],
   "source": [
    "plt.semilogy(np.abs(error)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cvs6QmtH--qm"
   },
   "source": [
    "# Inverse Power iteration\n",
    "\n",
    "What if we are interested in the smaller eigenvalue in magnitude?\n",
    "\n",
    "Suppose ${\\bf x},\\lambda$ is an eigenpair of ${\\bf A}$, such that ${\\bf A}{\\bf x}  = \\lambda {\\bf x}$. What would be an eigenvalue of  ${\\bf A}^{-1}$?\n",
    "\n",
    "\n",
    "$${\\bf A}^{-1}{\\bf A}{\\bf x}  = {\\bf A}^{-1}\\lambda {\\bf x}$$\n",
    "\n",
    "$${\\bf I}{\\bf x}  =  \\lambda {\\bf A}^{-1} {\\bf x}$$\n",
    "\n",
    "$$\\frac{1}{\\lambda}{\\bf x}  =  {\\bf A}^{-1} {\\bf x}$$\n",
    "\n",
    "\n",
    "** Hence $\\frac{1}{\\lambda}$ is an eigenvalue of ${\\bf A}^{-1} $ **.\n",
    "\n",
    "If we want to find the smallest eigenvalue in magnitude of ${\\bf A}$, we can perform power iteration using the matrix ${\\bf A}^{-1}$ to find $\\bar\\lambda = \\frac{1}{\\lambda}$, where  $\\bar\\lambda$ is the largest eigenvalue of ${\\bf A}^{-1}$.\n",
    "\n",
    "Let's implement that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_c0wO_bK--qn"
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "D = np.diag([5,-1,2,7])\n",
    "\n",
    "A = U@D@U.T\n",
    "eigl, eigv = la.eig(A)\n",
    "\n",
    "eig_index_sort = np.argsort(abs(eigl))\n",
    "eig_index_sort\n",
    "eigpos = eig_index_sort[0]\n",
    "\n",
    "print(eigv[:,eigpos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEJ_RQY---qs"
   },
   "outputs": [],
   "source": [
    "x0 = np.random.random(n)\n",
    "nrm = la.norm(x0)\n",
    "x = x0/nrm\n",
    "\n",
    "for i in range(20):\n",
    "    x = la.inv(A)@x\n",
    "    x = x/la.norm(x)\n",
    "\n",
    "print(\"lambdan = \",x.T@A@x/(x.T@x))\n",
    "print(\"un = \", x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUbG3PD8--qu"
   },
   "source": [
    "Can you find ways to improve the code snippet above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2SPkIPC--qv"
   },
   "outputs": [],
   "source": [
    "#Inverse Power iteration to get smallest eigenvalue\n",
    "x0 = np.random.random(n)\n",
    "nrm = la.norm(x0)\n",
    "x = x0/nrm\n",
    "P, L, Um = sla.lu(A)\n",
    "for k in range(20):\n",
    "    y = sla.solve_triangular(L, np.dot(P.T, x), lower=True)\n",
    "    x = sla.solve_triangular(Um, y)\n",
    "    x = x/la.norm(x)\n",
    "\n",
    "print(\"lambdan = \",x.T@A@x/(x.T@x))\n",
    "print(\"un = \", x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--cUJzDr--qy"
   },
   "source": [
    "# Inverse Shifted Power Iteration\n",
    "\n",
    "What if we want to find another eigenvalue that is not the largest or the smallest? \n",
    "\n",
    "Suppose ${\\bf x},\\lambda$ is an eigenpair of ${\\bf A}$, such that ${\\bf A}{\\bf x}  = \\lambda {\\bf x}$. We want to find the eigenvalues of the shifted inverse matrix $({\\bf A} - \\sigma{\\bf I})^{-1}$\n",
    "\n",
    "\n",
    "$$({\\bf A} - \\sigma{\\bf I})^{-1}{\\bf x}  = \\bar\\lambda {\\bf x}$$\n",
    "\n",
    "$${\\bf I}{\\bf x}  =  \\bar\\lambda ({\\bf A} - \\sigma{\\bf I}) {\\bf x} = \\bar\\lambda ({\\lambda \\bf I} - \\sigma{\\bf I}) {\\bf x}$$\n",
    "\n",
    "$$  \\bar\\lambda  = \\frac{1}{\\lambda-\\sigma}$$\n",
    "\n",
    "\n",
    "We could write the above eigenvalue problem as \n",
    "\n",
    "\n",
    "$$ {\\bf B}^{-1}{\\bf x}  = \\bar\\lambda {\\bf x}$$\n",
    "\n",
    "which can be solved by inverse power iteration, which will converge to the eigenvalue $\\frac{1}{\\lambda-\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRPuEI7s--qy"
   },
   "outputs": [],
   "source": [
    "n = 4\n",
    "D = np.diag([5,-7,2,10])\n",
    "\n",
    "A = U@D@U.T\n",
    "eigl, eigv = la.eig(A)\n",
    "\n",
    "print(eigl)\n",
    "eigv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKbvFpBF--q1"
   },
   "outputs": [],
   "source": [
    "#Shifted Inverse Power iteration \n",
    "sigma = 1\n",
    "\n",
    "x0 = np.random.random(n)\n",
    "nrm = la.norm(x0)\n",
    "x = x0/nrm\n",
    "B = A - sigma*np.eye(n)\n",
    "P, L, Um = sla.lu(B)\n",
    "for k in range(20):\n",
    "    y = sla.solve_triangular(L, np.dot(P.T, x), lower=True)\n",
    "    x = sla.solve_triangular(Um, y)\n",
    "    x = x/la.norm(x)\n",
    "\n",
    "print(\"lambdan = \",x.T@A@x/(x.T@x))\n",
    "print(\"un = \", x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWYGhYaI--q3"
   },
   "source": [
    "# Computational cost and convergence\n",
    "\n",
    "- power iteration: to obtain largest eigenvalue in magnitude ${\\lambda_1}$\n",
    "    - Matrix-vector multiplications at each iteration: $O(n^2)$\n",
    "    - convergence rate: $\\left|\\frac{\\lambda_2}{\\lambda_1} \\right|$\n",
    "    \n",
    "   \n",
    "- inverse power iteration: to obtain smallest eigenvalue in magnitude ${\\lambda_n}$\n",
    "    - only one factorization: $O(n^3)$\n",
    "    - backward-forward substitutions to solve at each iteration: $O(n^2)$\n",
    "    - convergence rate: $\\left|\\frac{\\lambda_n}{\\lambda_{n-1}} \\right|$  \n",
    "    \n",
    "   \n",
    "- inverse shifted power iteration: to obtain an eigenvalue close to a known/given value $\\sigma$\n",
    "    - only one factorization: $O(n^3)$\n",
    "    - backward-forward substitutions to solve at each iteration: $O(n^2)$\n",
    "    - convergence rate: $\\left|\\frac{\\lambda_c - \\sigma}{\\lambda_{c2} - \\sigma} \\right|$  \n",
    "    where $\\lambda_c$ is the closest eigenvalue to $\\sigma$ and $\\lambda_{c2}$ is the second closest eigenvalue to $\\sigma$.\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "12-eigen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
