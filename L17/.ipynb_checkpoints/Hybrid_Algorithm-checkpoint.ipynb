{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.seterr(divide='ignore');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Newton's method with Bisection\n",
    "\n",
    "Newton's method features a quadratic convergence rate, but is not guaranteed to converge unless the algorithm is started sufficiently close to the root of a function $f$.  For example, the function\n",
    "\n",
    "$$ f(x) = \\tanh(20x)$$\n",
    "\n",
    "where `tanh` is the hyperbolic tangent function, has a single root at $x = 0$. Newton's method will quickly diverge even with initial guesses at modest distances from the root."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function `f(x)` that returns the function value $f(x)$ defined above.\n",
    "\n",
    "Write the function `df(x)` that returns the function derivative $f'(x)$. Recall that:\n",
    "\n",
    "$$\\frac{d}{dz}\\tanh(z) = 1 - \\tanh^2(z)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (enter your code in this cell - DO NOT DELETE THIS LINE) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the function and its derivative over the interval $[-2,2]$.  Use two different plots for the function and its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = -2\n",
    "b0 = 2\n",
    "\n",
    "xmesh = np.linspace(a0, b0,200)\n",
    "plt.plot(xmesh, f(xmesh))\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title('$f(x)$')\n",
    "plt.show()\n",
    "plt.plot(xmesh,df(xmesh))\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.title('$f\\'(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice that $f'(x) \\approx 0$ for most values of the input $x$.  Newton's method, which is given by:\n",
    "\n",
    "$$ x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}$$\n",
    "\n",
    "will divide by a very small number unless $x_k \\approx 0$.\n",
    "\n",
    "Even with a starting guess of $x_0 = 0.06$, Newton's method will diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = [0.06]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Evaluate the next cell many times in-place (using Ctrl-Enter)\n",
    "The green dot is the current guess, and the orange line is the corresponding tangent line.  The next iterate will be where the tangent line intersects $x$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = guesses[-1] # grab last guess\n",
    "slope = df(x)\n",
    "\n",
    "# plot approximate function\n",
    "plt.plot(xmesh, f(xmesh))\n",
    "plt.plot(xmesh, f(x) + slope*(xmesh-x))\n",
    "plt.plot(x, f(x), \"o\")\n",
    "plt.xlim([-2, 2])\n",
    "plt.ylim([-2, 2])\n",
    "plt.axhline(0, color=\"black\")\n",
    "\n",
    "# Compute approximate root\n",
    "xnew = x - f(x) / slope\n",
    "guesses.append(xnew)\n",
    "\n",
    "print('Next iterate will be: ', xnew)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the bisection method will always find the root of this function, as long as the initial interval endpoints are of opposite sign.  It will not converge as fast as Newton's method, however.  To get the best of both worlds, we can combine the two as follows.\n",
    "\n",
    "### In this notebook, you will write a function that combines the two ideas:\n",
    "\n",
    "```python\n",
    "def bisection_Newton(a,b,tol,maxiter):\n",
    "    \n",
    "    # write your code here following the steps below\n",
    "    \n",
    "    return xstar, steps\n",
    "\n",
    "```\n",
    "\n",
    "Your function takes as arguments the initial interval `a` and `b`, the tolerance for the stopping criteria `tol` and the maximum number of iterations `maxiter`. When successful, the function returns the float variable `xstar` with the root obtained by the method, and the tuple `steps` that we will describe soon.\n",
    "\n",
    "Before implementing the function, we will guide you through the **steps needed to write this hybrid algorithm**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1)** Check if the initial interval $[a,b]$ is a valid interval. Recall that for the bisection method, we require $f(a)\\cdot f(b) < 0$ (so that the function values have opposite signs).  \n",
    "\n",
    "If $f(a)\\cdot f(b) > 0$ the algorithm should stop, and the function should return the string `Root is not bracketed by interval. Stop.`.\n",
    "\n",
    "Start writing the function `bisection_Newton(a,b,tol,maxiter)` in the `#grade` cell below with only this step 1) -- you will receive partial credit for that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (enter your code in this cell - DO NOT DELETE THIS LINE) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2)** The algorithm will try to first run a Newton iteration:\n",
    "\n",
    "$$ x_{new} = x_{old} + s $$\n",
    "\n",
    "where $s = -f(x_{old})/f'(x_{old})$ is the Newton step.\n",
    "\n",
    "For $x_{old}$, the hybrid algorithm will use one of the interval boundaries, either $a$ or $b$. We will use the function values to make that decision. \n",
    "\n",
    "We have two options:\n",
    "\n",
    "- set $x_{old} = \\text{argmin}_{x=a,b} |f(x)|$\n",
    "\n",
    "or\n",
    "\n",
    "- set $x_{old} = \\text{argmax}_{x=a,b} |f(x)|$\n",
    "\n",
    "Discuss with your team which one you should choose. Remember that you are trying to find $f(x_{new}) = 0$.\n",
    "\n",
    "Write the function `current_newton_step` that takes as arguments `(a,b,fa,fb)` where `fa = f(a)` and `fb = f(b)`, and returns `(xold, f(xold))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (enter your code in this cell - DO NOT DELETE THIS LINE) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this hybrid method, the first attempt is to use Newton Method as the update rule, since it has faster convergence when close to the solution. However, if the Newton iteration takes us outside the interval $(a,b)$, then we are not getting any closer to the desired root, and may even be diverging.  In this case, we fall back to the bisection method. In summary, we first try:\n",
    "\n",
    "$x_{new} = x_{old} - \\frac{f(x_{old})}{f'(x_{old})}$\n",
    "\n",
    "and if $x_{new} \\geq b$ or $x_{new} \\leq a$, we scrap this value of $x_{new}$ and use the bisection method instead:\n",
    "\n",
    "$ x_{new} = \\frac{a + b}{2}$.\n",
    "\n",
    "\n",
    "Using the same criteria as the standard bisection method, we then update either $a$ or $b$ to have the value $x_{new}$.  We then repeat the process and choose the next value of $x_{old}$ as defined above.  We can terminate whenever $|f(x_{old})| < \\text{tol}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will help you implemeting this algorithm into the function `bisection_Newton`.** I suggest you copy/paste your previous function definition in the new `#grade` cell below. We will provide several steps, so you can slowly construct the entire function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (enter your code in this cell - DO NOT DELETE THIS LINE) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PrairieLearn will only have tests for the complete function. It will not make sense to click \"Save & Grade\" until you complete the implementation of the function (just make sure you click at least once to register your attendance).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the steps below to the above function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3)**: We will start the iterative process. To make sure we don't get into an infinite loop, or iterate too many times, we will use a `for loop`, iterating for at most `maxiter`.  Later we will define a stopping criteria to break out of the for loop.\n",
    "\n",
    "The next steps will build the for loop block:\n",
    "\n",
    "\n",
    "**Step 4)**: Find the current point for the Newton Method using the function `current_newton_step(a,b,fa,fb)`. \n",
    "\n",
    "**Step 5)**: Compute `xnew` using the Newton update.\n",
    "\n",
    "**Step 6)**: Set the variable `method = Newton` (since you are attempting to use the Newton Method first).\n",
    "\n",
    "**Step 7)**: You should now check if Newton Method was a \"good option\". If the update `xnew` is outside of the interval `(a,b)`, then Newton Method \"failed\". In that case, you need to re-compute `xnew` using the Bisection method. Set the variable `method = Bisection`, indicating the current iteration is actually using the Bisection method. If the update `xnew` is inside the interval, then we continue with this update.\n",
    "\n",
    "**Step 8)**: Once you have the value of `xnew`, which is guaranteed to be inside the interval `[a,b]`, you need to update the interval for the next iteration.\n",
    "\n",
    "  - use the bisection algorithm, which looks at the sign of the functions, to decide if the next interval should be `[a,xnew]` or `[xnew,b]` . In essence, in this step, you need to update the values of `a` and `b`, and their respective function values `fa` and `fb`.\n",
    "  \n",
    "**Step 9)**: Update the list `steps` (that you should define as an empty list before the for loop block) to append the tuple `(abs(f(xnew)), method)`, so that you can have a history of the iterative process.\n",
    "\n",
    "**Step 10)**: Implement a stopping criteria, terminating the iterations whenever $|f(x_{old})| < \\text{tol}$. \n",
    "\n",
    "\n",
    "**Step 10)**: To finalize, your function should return `xnew` and `steps`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, if you call your function `c, steps = bisection_Newton(-2,5,1e-8,100)` you would get the following result for the variable `steps`:\n",
    "\n",
    "\n",
    "```\n",
    "[(1.0, 'Bisection'),\n",
    " (0.9999092042625951, 'Bisection'),\n",
    " (0.9999999999722241, 'Bisection'),\n",
    " (0.9988944427261528, 'Bisection'),\n",
    " (0.5545997223493823, 'Bisection'),\n",
    " (0.17416574680846925, 'Newton'),\n",
    " (0.003654552196927575, 'Newton'),\n",
    " (3.2540049472768056e-08, 'Newton'),\n",
    " (2.0679515313825692e-23, 'Newton')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew, steps = bisection_Newton(-2,5,1e-8,100)\n",
    "print(xnew)\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
